{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нейронные сети (продолжение)\n",
    "Пензин М.С.\n",
    "\n",
    "penzin.ml.tsu@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 9\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Классификация изображений\n",
    "\n",
    "Здесь нужно определить один или несколько классов, которые соответствуют некому изображению.\n",
    "\n",
    "Хорошим подспорьем стало создание [ImageNet](https://image-net.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AlexNet\n",
    "\n",
    "Одна из первых успешных нейронных сетей, которые показали, что нейронные сети способны решать сложные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/10/AlexNet-1-1.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VGG Net\n",
    "\n",
    "Использует идеи AlexNet, но создатели решили использовать максимально простые фильтры и использовать несколько подряд идущих сверточных слоев (это позволило уменьшить количество параметров).\n",
    "\n",
    "Как пример: фильтр 5х5 покрывает ту же площадь, что и два слоя с фильтром 3х3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GoogLeNet\n",
    "\n",
    "Google решил пойти по другому пути и создал самую сложную нейронную сеть на тот момент. Была создана сеть безумной глубины. Для компенсации этой глубины при обучении использовали вспомогательные выводы. \n",
    "\n",
    "Интересным моментом является использование фильтров размером 1х1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://miro.medium.com/max/5176/1*ZFPOSAted10TPd3hBQU8iQ.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Inception\n",
    "\n",
    "<center>\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-17-11-14-10.png\">\n",
    "</center>\n",
    "\n",
    "Интересным моментом тут является использование фильтра 1х1 для уменьшения размерности данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ResNet\n",
    "\n",
    "В недрах Microsoft родилась более интересная и простая идея. Это первая сеть, которая получала ошибку на пяти ведущих категориях меньше, чем ошибка человека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://test.neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://miro.medium.com/max/2628/1*S3TlG0XpQZSIpoDIUCQ0RQ.jpeg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Сегментация изображений\n",
    "\n",
    "Здесь стоит задача разбить изображение на отдельные сегменты.\n",
    "\n",
    "По большей части для сегментации изображений используют концепцию кодер-декодер. Базовой классикой является U-net, которая потом превратилась в SAUNet (лучшая сеть на 2020 год)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# U-net\n",
    "\n",
    "<center>\n",
    "<img style=\"max-height: 500px;\" src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Обнаружение объектов\n",
    "\n",
    "Здесь стоит задача найти объект некого типа на изображении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# YOLO\n",
    "\n",
    "Это одна из быстрейших и точнейших моделей в мире. Позволяет проводить обнаржение объектов в режиме реального времени. Может быть даже запущено в браузере через tensorflow.js\n",
    "\n",
    "<center>\n",
    "<img style=\"height: 300px; width: auto;\" src=\"https://miro.medium.com/max/640/1*vHWIzPbxmKQSZC6fOyK8Ug.gif\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img style=\"height: 600px; width: auto;\" src=\"https://i.stack.imgur.com/OPGDq.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Машинный перевод\n",
    "\n",
    "Здесь мы стремимся преобразовать одну последовательность в другую последовательноcть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея в машинном переводе - это получить некий контекст на основе текущего текста, а потом декодировать его в другой текст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seq2Seq\n",
    "\n",
    "Это прямая реализация идеи. Используется любая реккурентная нейронная сеть для формирования контекста, а потом его просто расшифровывают"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://docs.chainer.org/en/stable/_images/seq2seq.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Механизм внимания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании Seq2Seq были проблемы при обработке больших текстов, для решения этих проблем был придуман механизм внимания (Attention).\n",
    "\n",
    "\n",
    "Данные механизм помогает сконцентрироваться нейронной сети именно на том, что ей интересно в данный момент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/attention_mechanism.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Как это работает:\n",
    "\n",
    "1) Для каждого $t$-го слова мы получаем вектор внутреннего состояния кодировщика\n",
    "\n",
    "$$\n",
    "h_t = f(x_t, h_{t-1})\n",
    "$$\n",
    "\n",
    "2) Для каждого внутреннего состояния $s_i$ декодера\n",
    "\n",
    "$$\n",
    "s_i = f(s_{i-1}, y_i, c_i)\n",
    "$$\n",
    "\n",
    "мы будем рассчитывать вектор контекста как сумму внутренних состояний кодировщика\n",
    "\n",
    "$$\n",
    "c_i = \\sum_t \\alpha_{it} h_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Коэффициенты $\\alpha_{ij}$ позволяют определить на чем декодировщику нужно сконцентрировать свое внимание. Один из вариантов\n",
    "\n",
    "$$\n",
    "\\alpha_{it} = \\frac{\n",
    "    \\exp(e_{it})\n",
    "}{\n",
    "    \\sum_t \\exp(e_{it})\n",
    "}\n",
    "$$\n",
    "где \n",
    "$$\n",
    "e_{it} = a (s_{i-1}, h_j)\n",
    "$$\n",
    "\n",
    "определяет то, как вывод сети связан со входом. Может определяться любым удобным способом, например через полносвязный слой нейронной сети или как скалярное произведение векторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://hsto.org/webt/cl/dv/9f/cldv9f7zdegsobuszn10hyy1nde.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer\n",
    "\n",
    "Довольно интересный подход к анализу текста, в котором отказываются от рекуррентный блоков. Дает более точные результаты и при более быстром обучении. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://hsto.org/webt/34/f7/lm/34f7lmnxvdcchib66hhxbdx8vzg.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Self-attention\n",
    "\n",
    "Рассмотрим, как работает механизм само-внимания. Каждое входное значение $x_i$ используется несколькими способами\n",
    "\n",
    "- (query) Это значение сравнивается с другими значениями, чтобы определить вес для собственного вывода $y_i$\n",
    "- (key) Это значение сравнивается с другими значениями, чтобы определить вес для остальных выводов $y_j$\n",
    "- (value) Используется как часть взешенной суммы для каждого выходного вектора, после того как все веса рассчитаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Фактически, мы рассчитываем промежуточные значения\n",
    "\n",
    "$$\n",
    "q_i = W_q x_i\n",
    "\\\\\n",
    "k_i = W_k x_i\n",
    "\\\\\n",
    "v_i = W_v x_i\n",
    "$$\n",
    "\n",
    "Рассчитываем веса\n",
    "$$\n",
    "w_{ij} = \\bf{softmax}(q_i^T k_j)\n",
    "$$\n",
    "\n",
    "Итоговое значение\n",
    "$$\n",
    "y_i = \\sum_j w_{ij} v_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"http://peterbloem.nl/files/transformers/key-query-value.svg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img style=\"height: 600px; width: auto;\" src=\"https://jalammar.github.io/images/t/transformer_self-attention_visualization.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multihead Self-Attention\n",
    "\n",
    "<center><img style=\"height: 600px; width: auto;\" src=\"https://hsto.org/webt/he/j3/f1/hej3f1fkxked2nrlj_xnz9k3vmy.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Блок кодировщика\n",
    "\n",
    "<center><img src=\"https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Декодер\n",
    "\n",
    "<center><img style=\"height: 600px; width: auto;\" src=\"https://jalammar.github.io/images/t/transformer_decoding_2.gif\"></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
